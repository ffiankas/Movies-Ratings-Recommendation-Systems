# -*- coding: utf-8 -*-
"""Recommendation System_Fatmah Fianka Syafrudin

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JND8R3-qPw5Wr7igD60E8Z_d7ltBJbP_

# Proyek Sistem Rekomendasi: Movies & Ratings for Recommendation System
- **Nama:** Fatmah Fianka Syafrudin
- **Email:** fatmahfiank17@gmail.com
- **ID Dicoding:** fianka
- **Dataset:** [Movies & Ratings for Recommendation System](https://www.kaggle.com/datasets/nicoletacilibiu/movies-and-ratings-for-recommendation-system)

# Problem Statements
- Pengguna kesulitan menemukan film yang sesuai dengan preferensi pribadi mereka karena terlalu banyak pilihan film yang tersedia di platform digital. Hal ini menyebabkan pengalaman pengguna menjadi kurang optimal dan dapat mengurangi minat menonton.

- Sistem rekomendasi konvensional sering kali belum memanfaatkan data historis pengguna secara optimal, sehingga belum mampu menyajikan rekomendasi yang benar-benar relevan dan personal.

- Kurangnya sistem rekomendasi yang secara efektif menggabungkan pendekatan berbasis konten (seperti genre film) dan kolaboratif (berdasarkan kesamaan preferensi antar pengguna), sehingga potensi data pengguna belum dimanfaatkan sepenuhnya untuk meningkatkan akurasi rekomendasi.

# Goals
- Meningkatkan pengalaman pengguna dalam memilih film dengan menghadirkan rekomendasi yang relevan berdasarkan preferensi pribadi pengguna, tanpa harus menelusuri ribuan pilihan secara manual.

- Membangun sistem rekomendasi film dengan dua pendekatan utama Content-Based Filtering dan Collaborative Filtering yang memanfaatkan data historis pengguna seperti rating dan genre film.

- Mengembangkan model yang mampu mengidentifikasi kemiripan antar film maupun pola preferensi antar pengguna, guna menyarankan film yang sesuai dengan minat pengguna.

# Data Understanding
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d nicoletacilibiu/movies-and-ratings-for-recommendation-system
!unzip movies-and-ratings-for-recommendation-system.zip

import pandas as pd

movies = pd.read_csv('movies.csv')
ratings = pd.read_csv('ratings.csv')

print('Jumlah film: ', len(movies.movieId.unique()))
print('Jumlah pengguna yang memberikan rating: ', len(ratings.userId.unique()))

"""# Univariate Exploratory Data Analysis

Pada proyek kali ini terdapat 2 dataset yaitu movies dan ratings.
Variabel-variabel pada kedua dataset adalah sebagai berikut:
- movies : berisi informasi film.
  - movieId: ID unik untuk setiap film
  - title: Judul film, biasanya mencakup nama film diikuti tahun rilis dalam tanda kurung.
  - genres: daftar genre film, bisa berisi satu atau beberapa genre yang relevan dengan film tersebut, jika terdapat lebih dari satu genre, mereka dipisahkan dengan tanda `|`.

- ratings : berisi data rating yang diberikan pengguna.
  - userId: ID unik untuk setiap pengguna yang memberikan rating.
  - movieId: ID film yang diberikan rating oleh pengguna.
  - rating: Nilai rating yang diberikan pengguna untuk film tersebut. Biasanya berupa skala penilaian 0.5 – 5.0 di mana nilai semakin tinggi angka berarti pengguna lebih menyukai film tersebut.
  - timestamp: timestamp yang menunjukkan kapan rating diberikan.

## Movies Variabel
"""

movies.info()

"""Dataset berisi 9742 baris dan 4 kolom."""

movies.head()

import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import pandas as pd

genre_list = [g for sublist in movies['genres'].str.split('|').tolist() for g in sublist]
top_genres = pd.Series(Counter(genre_list)).sort_values(ascending=False).head(10)

colors = ['#FF5733'] + ['#3498DB'] * (len(top_genres) - 1)

plt.figure(figsize=(10, 6))
bars = sns.barplot(x=top_genres.index, y=top_genres.values, color='#3498DB')

for bar, color in zip(bars.patches, colors):
    bar.set_color(color)

for bar in bars.patches:
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        bar.get_height() + 1,
        f'{int(bar.get_height())}',
        ha='center',
        va='bottom',
        fontsize=10,
    )

plt.title("10 Genre Terpopuler", fontsize=14, fontweight='bold')
plt.ylabel("Jumlah Film")
plt.xlabel("Genre")

plt.tight_layout()
plt.show()

"""Dapat dilihat pada grafik Top 10 Genre Terpopuler  menunjukkan bahwa genre terbanyak adalah Drama dengan total 4361 film, diikuti dengan Comedy, Thriller, Action, Romance, Adventure, Crime, Sci-Fi, Horror dan yang terakhir Fantasy.

## Ratings Variable
"""

ratings.info()

"""Terdapat 100836 baris dan 4 kolom."""

ratings.head()

plt.figure(figsize=(6, 4))
bars = sns.countplot(x='rating', data=ratings, color='#3498DB')

heights = [bar.get_height() for bar in bars.patches]
max_height = max(heights)
max_index = heights.index(max_height)

bars.patches[max_index].set_color('#FF5733')

plt.title("Distribusi Rating Film")
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.show()

"""Dapat dilihat bahwa rating 4.0 adalah yang paling sering diberikan untuk film yang ditonton. Sementara rating rendah seperti 0.5, 1.0, dan 1.5 cenderung jarang diberikan oleh pengguna.

# Data Preparation
"""

print('Duplikasi data pada movies:', movies.duplicated().sum())
print('Duplikasi data pada ratings:', ratings.duplicated().sum())

print("Missing values pada movies:")
print(movies.isnull().sum())

print("Missing values pada ratings:")
print(ratings.isnull().sum())

"""Melakukan pengecekan duplikasi data dan
nilai null, dapat dilihat bahwa tidak terdapat duplikasi data dan nilai null sehingga tidak perlu dilakukan penanganan seperti penghapusan data yang terdapat duplikat atau nilai null.

# Model Development Content Based Filtering

## TF-IDF Vectorizer
"""

movies['genres'] = movies['genres'].str.replace('|',' ',regex=False)

"""Melakukan transformasi pada kolom genres di movies_df untuk keperluan model Content-Based Filtering. Pada dataset movies, setiap film memiliki daftar genre yang dituliskan dalam satu kolom sebagai string, di mana masing-masing genre dipisahkan oleh simbol pipe (|). Sebelum melakukan pemodelan Content Based, delimiter | ini diubah menjadi spasi. Contohnya, genre “Action|Adventure|Comedy” akan diubah menjadi “Action Adventure Comedy”. Perubahan ini bertujuan agar setiap genre dapat diperlakukan sebagai kata terpisah ketika teks genre tersebut diproses lebih lanjut."""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()
tf.fit(movies['genres'])
tf.get_feature_names_out()

tfidf_matrix = tf.fit_transform(movies['genres'])
tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=movies.title
).sample(15, axis=1, replace=True).sample(5, axis=0)

"""Pada tahap ini, dilakukan pembentukan fitur konten film dengan menerapkan metode TF-IDF pada data genre. Metode ini menghasilkan representasi numerik dalam bentuk vektor untuk setiap film, yang mencerminkan tingkat kepentingan setiap genre bagi film tersebut dibandingkan dengan film lainnya.

Setiap film diwakili oleh vektor berdimensi 24, di mana setiap nilai menunjukkan relevansi suatu genre terhadap film tersebut. Genre yang memang dimiliki oleh film akan mendapatkan bobot lebih tinggi, khususnya jika genre tersebut jarang muncul di film lain. Film-film dengan genre serupa akan memiliki pola nilai TF-IDF yang cenderung mirip.

## Cosine Similarity
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=movies['title'], columns=movies['title'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Pada tahap ini, dilakukan penghitungan tingkat kemiripan antar film dengan menggunakan vektor TF-IDF dari genre yang telah dibentuk sebelumnya. Metode yang digunakan adalah Cosine Similarity, yaitu metrik yang mengukur kemiripan dua vektor berdasarkan sudut di antara keduanya. Nilai cosine similarity yang mendekati 1 menunjukkan bahwa dua film memiliki genre yang sangat mirip, sedangkan nilai yang mendekati 0 menunjukkan perbedaan genre yang signifikan.

## Mendapatkan Rekomendasi
"""

def movies_recommendations(movies_name, similarity_data=cosine_sim_df, items=movies[['movieId','title', 'genres']], k=10):
    index = similarity_data.loc[:,movies_name].to_numpy().argpartition(
        range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(movies_name, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

movies[movies.title.eq('Pacific Rim (2013)')]

movies_recommendations('Pacific Rim (2013)')

"""Pada tahap ini, dibuat sebuah fungsi rekomendasi yang menerima input berupa judul film, lalu mencari dan menampilkan film lain dengan genre paling serupa menggunakan matriks cosine similarity yang telah dihitung sebelumnya.

## Metrik Evaluasi Content Based Filtering
"""

def precision_at_k(recommended, relevant, k=10):
    recommended_at_k = recommended[:k]
    hits = sum([1 for rec in recommended_at_k if rec in relevant])
    return hits / k

recommended_movies = [106002, 46530, 68358, 8636, 93363, 82461, 111364, 102445, 103228, 5378]

genre_target = movies[movies.title == 'Avengers, The (2012)']['genres'].values[0]
relevant_movies = set(movies[movies.genres == genre_target]['movieId'].values)

print("Precision@10:", precision_at_k(recommended_movies, relevant_movies, k=10))

"""# Model Development dengan Collaborative Filtering

## Data Preparation
"""

import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

df = ratings
df.drop('timestamp', axis=1, inplace=True)
df

user_ids = df['userId'].unique().tolist()
print('list userId: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

movies_ids = df['movieId'].unique().tolist()

movies_to_movies_encoded = {x: i for i, x in enumerate(movies_ids)}

movies_encoded_to_movies = {i: x for i, x in enumerate(movies_ids)}

df['user'] = df['userId'].map(user_to_user_encoded)

df['movie'] = df['movieId'].map(movies_to_movies_encoded)

num_users = len(user_to_user_encoded)
print(num_users)

num_movies = len(movies_encoded_to_movies)
print(num_movies)

df['rating'] = df['rating'].values.astype(np.float32)

min_rating = min(df['rating'])

max_rating = max(df['rating'])

print('Number of User: {}, Number of movies: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movies, min_rating, max_rating
))

"""Pada tahap ini, data dipersiapkan untuk model Collaborative Filtering dengan mengubah userId dan movieId menjadi indeks integer berurutan mulai dari 0. Proses encoding ini penting karena model machine learning menggunakan indeks tersebut sebagai input untuk embedding, yang biasanya memerlukan nilai indeks integer yang berurutan dari 0 hingga N-1.

## Membagi Data untuk Training dan Validasi
"""

df = df.sample(frac=1, random_state=42)
df

x = df[['user', 'movie']].values

y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Pada tahap ini dilakukan proses normalisasi rating serta pembagian data menjadi set pelatihan dan validasi. Normalisasi rating bertujuan untuk membatasi rentang nilai target yang akan diprediksi oleh model. Dalam kasus ini, rating asli yang berada di rentang 0,5 hingga 5,0 diubah menjadi skala 0 hingga 1 menggunakan metode min-max scaling, yaitu dengan rumus: (rating - min\_rating) / (max\_rating - min\_rating). Dengan nilai min\_rating = 0,5 dan max\_rating = 5,0, maka rating 0,5 akan diubah menjadi 0,0 dan rating 5,0 menjadi 1,0.

Setelah proses normalisasi selesai, data kemudian dibagi menjadi dua bagian: 80% untuk data pelatihan dan 20% untuk data validasi. Pembagian ini dilakukan agar model dapat diuji performanya pada data yang belum pernah dilihat selama pelatihan.

## Proses Training
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movies, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movies = num_movies
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.movies_embedding = layers.Embedding(
        num_movies,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movies_bias = layers.Embedding(num_movies, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    movies_vector = self.movies_embedding(inputs[:, 1])
    movies_bias = self.movies_bias(inputs[:, 1])

    dot_user_movies = tf.tensordot(user_vector, movies_vector, 2)

    x = dot_user_movies + user_bias + movies_bias

    return tf.nn.sigmoid(x)

model = RecommenderNet(num_users, num_movies, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 512,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""Tahap ini melibatkan perancangan arsitektur model Collaborative Filtering yang berupa neural network dengan penggunaan embedding layers untuk merepresentasikan pengguna dan film. Inti dari model ini adalah mempelajari vektor embedding untuk setiap pengguna dan film, kemudian menghitung hasil dot product antara vektor pengguna dan film sebagai prediksi tingkat kesukaan (rating). Selain itu, model juga menambahkan bias khusus untuk setiap pengguna dan film sebelum melakukan proses pelatihan.

## Visualisasi Metrik
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Performa model yang diukur menggunakan RMSE menunjukkan hasil yang baik dengan nilai di bawah 1.0 pada data validasi, yang berarti rata-rata kesalahan prediksi kurang dari 1 poin. Nilai RMSE pada data pelatihan yang lebih rendah dibandingkan validasi mengindikasikan model mampu mempelajari data latih dengan baik, namun selisih yang cukup besar antara keduanya menandakan kemungkinan terjadi overfitting.

## Mendapat Rekomendasi Film
"""

movies_df = movies
ratings_df = ratings

user_id = ratings_df.userId.sample(1).iloc[0]
movies_watched_by_user = ratings_df[ratings_df.userId == user_id]

movie_not_watched = movies_df[~movies_df['movieId'].isin(movies_watched_by_user.movieId.values)]['movieId']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movies_to_movies_encoded.keys()))
)

movie_not_watched = [[movies_to_movies_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movies_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

ratings = model.predict(user_movies_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movies_ids = [
    movies_encoded_to_movies.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('movies with high ratings from user')
print('----' * 8)

top_movies_user = (
    movies_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movies_df_rows = movies_df[movies_df['movieId'].isin(top_movies_user)]
for row in movies_df_rows.itertuples():
    print(row.title, ':', row.genres)

print('----' * 8)
print('Top 10 movies recommendation')
print('----' * 8)

recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movies_ids)]
for row in recommended_movies.itertuples():
    print(row.title, ':', row.genres)

"""Pada tahap ini dilakukan proses pembuatan rekomendasi film untuk pengguna tertentu dengan menggunakan model collaborative filtering yang sudah dilatih. Berbeda dengan metode content-based yang mengandalkan kemiripan antar film, pendekatan ini berdasarkan pada preferensi pengguna dan pola rating dari pengguna lain. Terdapat daftar 10 film rekomendasi untuk pengguna yang dipilih, yang berisi film-film belum pernah ditonton oleh pengguna tersebut, disusun berdasarkan prediksi rating tertinggi hingga terendah. Film nomor satu di daftar merupakan film yang diperkirakan paling disukai oleh pengguna menurut model."""

movies = pd.read_csv('movies.csv')
ratings = pd.read_csv('ratings.csv')

merged = ratings.merge(movies, on='movieId', how='left')
data_user = merged[merged['userId'] == user_id]
best_movies = data_user.sort_values(by='rating', ascending=False).head(10)

plt.figure(figsize=(10,5))
sns.barplot(y='title', x='rating', data=best_movies, palette='coolwarm')
plt.title(f'10 Film dengan Rating Tertinggi oleh User {user_id}')
plt.xlabel('Rating')
plt.ylabel('Judul Film')
plt.tight_layout()
plt.show()

"""Pada tahap ini, dilakukan visualisasi film-film dengan rating tertinggi dari seorang pengguna tertentu. Visualisasi tersebut memudahkan pemahaman terhadap preferensi pengguna berdasarkan riwayat rating yang diberikan. Grafik menampilkan 10 film dengan rating tertinggi yang telah diberikan oleh pengguna yang sebelumnya direkomendasikan."""